# ğŸ³ docker-ai-models

**Production-Ready Dockerfiles for AI Models â€“ Zero Setup, Maximum Results**

Transform complex AI model deployments into simple Docker commands. This repository provides optimized, tested containers for cutting-edge AI models across music, video, image, and text generation. No dependency hell, no environment conflicts â€“ just pull, run, and create.

---

## ğŸ“¦ Repository Structure

Each model has its own folder containing:

- `dockerfile` / `dockerfile-gpu-poor` â€“ Container build files optimized for different hardware configurations
- `startup.sh` / `startup-gpu-poor.sh` â€“ Automated setup and launch scripts
- Model-specific configurations and optimizations

Current structure:

```bash
â”œâ”€â”€ yue/                    # YuE: Full-song music generation
â”‚   â”œâ”€â”€ dockerfile          # Standard GPU build (24GB+ VRAM)
â”‚   â”œâ”€â”€ dockerfile-gpu-poor # Lightweight build (8GB+ VRAM)
â”‚   â”œâ”€â”€ startup.sh          # Standard launch script
â”‚   â””â”€â”€ startup-gpu-poor.sh # GPU-constrained launch script
â”œâ”€â”€ wan/                    # Wan2GP: Video-to-audio generation
â”‚   â”œâ”€â”€ dockerfile-gpu-poor # GPU-efficient build
â”‚   â””â”€â”€ startup-gpu-poor.sh # Launch script
```

---

## âœ¨ Featured AI Models

| Model | Type | Hardware | Interface | Documentation |
|-------|------|----------|-----------|---------------|
| ğŸµ **YuE** | Lyrics-to-Song Generation | 24GB+ VRAM | Web UI + CLI | [Setup Guide](yue/README.md) |
| ğŸ¶ **YuE-GP** | Music Generation (Optimized) | 8GB+ VRAM | Web UI | [Setup Guide](yue/README-GPU-POOR.md) |
| ğŸ¬ **Wan2GP** | Video-to-Audio Synthesis | 8GB+ VRAM | Web UI | *Coming Soon* |

### ğŸš€ Quick Start

Choose your model and run a single command:

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/docker-ai-models.git
cd docker-ai-models

# Navigate to your chosen model
cd yue/  # or wan/

# Build and run (see individual README files for specific commands)
docker build -f dockerfile -t model:latest .
docker run --gpus all -p 7860:7860 model:latest
```

Open `http://localhost:7860` in your browser and start creating!

---

## ğŸ¯ Why Choose This Repository?

- **ğŸ”§ Zero Configuration** â€“ No dependency hunting, no environment conflicts
- **âš¡ Hardware Optimized** â€“ Multiple builds for different GPU capabilities
- **ğŸŒ Web Interfaces** â€“ Beautiful, intuitive web UIs for all models
- **ğŸ“¦ Production Ready** â€“ Tested, stable containers ready for deployment
- **â±ï¸ Time Saving** â€“ From hours of setup to minutes of runtime
- **ğŸ”„ Reproducible** â€“ Same results, every time, everywhere

---

## ğŸ› ï¸ How It Works

Each model directory contains:
- **Optimized Dockerfiles** for different hardware configurations
- **Automated startup scripts** handling all dependencies
- **Comprehensive documentation** with step-by-step guides
- **Web interfaces** providing intuitive controls and real-time feedback

---

## ğŸ¤ Contributing

Have an AI model you'd like to containerize? We'd love your contribution!

1. Fork this repository
2. Create a new directory: `your-model-name/`
3. Add `dockerfile`, `startup.sh`, and `README.md`
4. Submit a pull request

---

## ğŸ“ License

MIT License â€“ free to use, modify, and distribute.

â­ **Star this repo** if it saves you time!